{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP - text classification\n",
    "Training using [Emotions dataset for NLP](https://www.kaggle.com/datasets/praveengovi/emotions-dataset-for-nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.9\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 22:34:52.624459: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-12 22:34:53.549493: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version:  1.26.4\n",
      "Tensorflow Version 2.16.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "\n",
    "print(\"NumPy version: \", np.__version__)\n",
    "print(\"Tensorflow Version\",tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence    label\n",
       "0                            i didnt feel humiliated  sadness\n",
       "1  i can go from feeling so hopeless to so damned...  sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong    anger\n",
       "3  i am ever feeling nostalgic about the fireplac...     love\n",
       "4                               i am feeling grouchy    anger"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"dataset/train.txt\",\n",
    "                 delimiter=';', header=None, names=['sentence','label'])\n",
    "\n",
    "df_valid = pd.read_csv(\"dataset/val.txt\",\n",
    "                 delimiter=';', header=None, names=['sentence','label'])\n",
    "\n",
    "df_test  = pd.read_csv(\"dataset/test.txt\",\n",
    "                 delimiter=';', header=None, names=['sentence','label'])\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "joy         5362\n",
       "sadness     4666\n",
       "anger       2159\n",
       "fear        1937\n",
       "love        1304\n",
       "surprise     572\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "joy        5362\n",
       "sadness    4666\n",
       "anger      2159\n",
       "fear       1937\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train[~df_train['label'].str.contains('love')]\n",
    "df_train = df_train[~df_train['label'].str.contains('surprise')]\n",
    "\n",
    "df_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = df_valid[~df_valid['label'].str.contains('love')]\n",
    "df_valid = df_valid[~df_valid['label'].str.contains('surprise')]\n",
    "\n",
    "df_test = df_test[~df_test['label'].str.contains('love')]\n",
    "df_test = df_test[~df_test['label'].str.contains('surprise')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_categories = len(df_train.label.unique())\n",
    "emotion_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split into X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_txt = df_train['sentence']\n",
    "train_label = df_train['label']\n",
    "\n",
    "valid_txt = df_valid['sentence']\n",
    "valid_label = df_valid['label']\n",
    "\n",
    "test_txt = df_test['sentence']\n",
    "test_label = df_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                              i didnt feel humiliated\n",
       "1    i can go from feeling so hopeless to so damned...\n",
       "2     im grabbing a minute to post i feel greedy wrong\n",
       "4                                 i am feeling grouchy\n",
       "5    ive been feeling a little burdened lately wasn...\n",
       "Name: sentence, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_txt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/physics/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                    didnt feel humili\n",
       "1    go feel hopeless damn hope around someon care ...\n",
       "2                 im grab minut post feel greedi wrong\n",
       "4                                         feel grouchi\n",
       "5            ive feel littl burden late wasnt sure whi\n",
       "Name: sentence, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from text_preprocess import preprocess_text\n",
    "\n",
    "train_txt.apply(lambda x: preprocess_text(x, do_stem=True)).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_txt = train_txt.apply(lambda x: preprocess_text(x, do_stem=True))\n",
    "valid_txt = valid_txt.apply(lambda x: preprocess_text(x, do_stem=True))\n",
    "test_txt  = test_txt.apply(lambda x: preprocess_text(x, do_stem=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3, 3, 0, 0, 3]), array([3, 3, 0, 2, 2]), array([3, 3, 3, 2, 3]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "train_label = encoder.fit_transform(train_label)\n",
    "valid_label = encoder.transform(valid_label)\n",
    "test_label = encoder.transform(test_label)\n",
    "\n",
    "train_label[:5], valid_label[:5], test_label[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = to_categorical(train_label)\n",
    "valid_y = to_categorical(valid_label)\n",
    "test_y = to_categorical(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stop Block ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words + DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_txt)\n",
    "tokenizer.word_index\n",
    "\n",
    "tokenizer.texts_to_matrix(train_txt, mode='count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = tokenizer.texts_to_matrix(train_txt, mode='count')\n",
    "valid_X = tokenizer.texts_to_matrix(valid_txt, mode='count')\n",
    "test_X  = tokenizer.texts_to_matrix(test_txt, mode='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14124, 9531), (1741, 9531), (1775, 9531))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, valid_X.shape, test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/physics/anaconda3/envs/ml/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-08-12 22:35:02.166201: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-12 22:35:02.342859: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">610,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m610,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m132\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">612,260</span> (2.34 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m612,260\u001b[0m (2.34 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">612,260</span> (2.34 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m612,260\u001b[0m (2.34 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nlp_model import nlp_dnn\n",
    "\n",
    "model = nlp_dnn((train_X.shape[1],), emotion_categories)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5468 - loss: 1.0777 - val_accuracy: 0.8845 - val_loss: 0.3681\n",
      "Epoch 2/10\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9293 - loss: 0.2343 - val_accuracy: 0.8932 - val_loss: 0.3136\n",
      "Epoch 3/10\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9671 - loss: 0.1106 - val_accuracy: 0.8909 - val_loss: 0.3526\n",
      "Epoch 4/10\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9745 - loss: 0.0747 - val_accuracy: 0.8914 - val_loss: 0.3886\n",
      "Epoch 5/10\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9854 - loss: 0.0491 - val_accuracy: 0.8857 - val_loss: 0.4452\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.8870 - loss: 0.4128\n",
      "Test Loss: 0.40749359130859375\n",
      "Test Accuracy: 0.8867605924606323\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_X, train_y, validation_data=(valid_X, valid_y), epochs=10, batch_size=32, callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)])\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_X, test_y)\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With bag of words, each input is a 9531-dimension vector. The test accuracy is 0.89."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stop Block ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze texts with padding sequences + Recurrent models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sentence_len = 0\n",
    "for sentence in train_txt:\n",
    "    max_sentence_len = max(max_sentence_len, len(sentence.split()))\n",
    "\n",
    "max_sentence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median sentence length: 9.0\n",
      "Quartiles: [ 5.  9. 13.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# collect statistics of sentence length\n",
    "sentences_len = np.array([len(sentence.split()) for sentence in train_txt])\n",
    "# find median, plot histogram\n",
    "median_len = np.median(sentences_len)\n",
    "quartiles = np.quantile(sentences_len, [0.25, 0.5, 0.75])\n",
    "print(\"Median sentence length:\", median_len)\n",
    "print(\"Quartiles:\", quartiles)\n",
    "_ = plt.hist(sentences_len, bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This statistics results show that it might be not be efficient enough to use maximum sentence length to pad sequences. However, we will still use max_sentence_len for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 10000\n",
    "# pad_size = max_sentence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(train_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9531\n",
      "feel 1\n",
      "like 2\n",
      "im 3\n",
      "not 4\n",
      "becaus 5\n"
     ]
    }
   ],
   "source": [
    "num_words = len(tokenizer.word_index) + 1\n",
    "print(num_words)\n",
    "for i in range(5):\n",
    "    key = list(tokenizer.word_index.keys())[i]\n",
    "    print(key, tokenizer.word_index[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['didnt', 'feel', 'humili'],\n",
       " ['go',\n",
       "  'feel',\n",
       "  'hopeless',\n",
       "  'damn',\n",
       "  'hope',\n",
       "  'around',\n",
       "  'someon',\n",
       "  'care',\n",
       "  'awak'],\n",
       " ['im', 'grab', 'minut', 'post', 'feel', 'greedi', 'wrong'],\n",
       " ['feel', 'grouchi']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from text_preprocess import text2sentences\n",
    "\n",
    "train_sentences = text2sentences(train_txt)\n",
    "train_sentences[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sure', 0.9847540855407715), ('topic', 0.983769953250885), ('go', 0.9833862781524658), ('person', 0.9828078150749207), ('punish', 0.9819080233573914), ('chose', 0.9815338253974915), ('belli', 0.9814921021461487), ('cant', 0.9814298748970032), ('smart', 0.9812914133071899), ('right', 0.9812730550765991)]\n",
      "Vector for 'feel': [-0.25207177  0.14792788  0.25043026  0.80379325 -0.82181364 -0.995705\n",
      "  1.1619874   1.5975789  -1.1887304  -0.6378109   0.3495718  -1.0352572\n",
      "  0.2585926   0.49965    -1.0612639   0.04673853  0.48523158  0.07277071\n",
      " -1.1791193  -0.8577896   0.15427719  1.1585777   0.80794066 -0.47041196\n",
      "  0.9142356   0.6315526  -0.4213455  -0.20390348 -0.91531575  0.05932346\n",
      "  0.07668488 -0.37411842 -0.04302233 -0.3458213  -0.4603439   0.8547294\n",
      "  0.7553368  -0.27786133  0.5301382  -0.84895873  0.2486916   0.6604347\n",
      "  0.07514174  0.12339656  1.2313205   0.5499689  -0.17516132 -0.0260135\n",
      "  0.17627525  0.3705529 ]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Training the model\n",
    "model_w2v = Word2Vec(train_sentences, vector_size=50, window=4, min_count=1, workers=8)\n",
    "\n",
    "# Finding similar words\n",
    "similar_words = model_w2v.wv.most_similar('feel')\n",
    "print(similar_words)\n",
    "word_vector = model_w2v.wv['feel']\n",
    "print(f\"Vector for 'feel': {word_vector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_dim': 9531,\n",
       " 'output_dim': 50,\n",
       " 'weights': [array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [-2.52071768e-01,  1.47927880e-01,  2.50430256e-01, ...,\n",
       "          -2.60134954e-02,  1.76275253e-01,  3.70552897e-01],\n",
       "         [-2.37250596e-01, -4.51893881e-02,  1.47369623e-01, ...,\n",
       "          -5.15173197e-01,  9.71006379e-02,  2.46713877e-01],\n",
       "         ...,\n",
       "         [-2.51545012e-02,  5.55335032e-03,  2.25344822e-02, ...,\n",
       "           9.17060825e-04, -1.04980888e-02,  7.98362494e-03],\n",
       "         [-2.55546503e-04,  1.55271105e-02,  1.60005186e-02, ...,\n",
       "          -9.69555229e-04,  5.65193826e-03, -1.03667509e-02],\n",
       "         [-3.57144047e-04,  6.53200597e-03, -1.30426856e-02, ...,\n",
       "          -1.05302166e-02,  9.30283312e-03, -1.03162043e-02]])]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from text_preprocess import get_embeddingdict_w2v\n",
    "\n",
    "embedding_dict = get_embeddingdict_w2v(tokenizer, model_w2v)\n",
    "embedding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14124, 36),\n",
       " array([[  62,    1,  540,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [  11,    1,  338,  717,   63,   55,   74,  165, 1016,    0],\n",
       "        [   3, 1355,  484,  106,    1,  390,  150,    0,    0,    0]],\n",
       "       dtype=int32))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = pad_sequences(tokenizer.texts_to_sequences(train_txt), maxlen=max_sentence_len, padding='post')\n",
    "\n",
    "train_X.shape, train_X[:3, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_X = pad_sequences(tokenizer.texts_to_sequences(valid_txt), maxlen=max_sentence_len, padding='post')\n",
    "test_X = pad_sequences(tokenizer.texts_to_sequences(test_txt), maxlen=max_sentence_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_model import nlp_lstm_embedding\n",
    "\n",
    "model = nlp_lstm_embedding(embedding_dict, emotion_categories)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.3640 - loss: 1.3087 - val_accuracy: 0.3986 - val_loss: 1.2798\n",
      "Epoch 2/10\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.3805 - loss: 1.2951 - val_accuracy: 0.3647 - val_loss: 1.2855\n",
      "Epoch 3/10\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.3759 - loss: 1.2953 - val_accuracy: 0.4032 - val_loss: 1.2797\n",
      "Epoch 4/10\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.3866 - loss: 1.2876 - val_accuracy: 0.3998 - val_loss: 1.2775\n",
      "Epoch 5/10\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.3810 - loss: 1.2921 - val_accuracy: 0.4044 - val_loss: 1.2778\n",
      "Epoch 6/10\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.3831 - loss: 1.2920 - val_accuracy: 0.4061 - val_loss: 1.2789\n",
      "Epoch 7/10\n",
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.3991 - loss: 1.2788 - val_accuracy: 0.4061 - val_loss: 1.2793\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">476,550</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ masking (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">21,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,368</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │       \u001b[38;5;34m476,550\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ masking (\u001b[38;5;33mMasking\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m21,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m10,368\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m132\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">571,796</span> (2.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m571,796\u001b[0m (2.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,748</span> (124.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,748\u001b[0m (124.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">476,550</span> (1.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m476,550\u001b[0m (1.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,498</span> (248.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m63,498\u001b[0m (248.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_X, train_y, validation_data=(valid_X, valid_y), epochs=10, batch_size=32, callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3790 - loss: 1.2986\n",
      "Test Loss: 1.2821530103683472\n",
      "Test Accuracy: 0.4000000059604645\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_X, test_y)\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is only a little better than random guessing (0.25) and is definitely not good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove\n",
    "Use pre-trained [GloVe model](https://nlp.stanford.edu/projects/glove/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_glove_file = \"glove.twitter.27B.50d.txt\" # \"glove.6B.50d.txt\"\n",
    "# embedding_dim = 50 # can be obtained from GloVe files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1193514 word vectors.\n",
      "Converted 7352 words (2178 misses)\n"
     ]
    }
   ],
   "source": [
    "from text_preprocess import get_embeddingdict_glove\n",
    "\n",
    "embedding_dict = get_embeddingdict_glove(tokenizer, path_to_glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size:  9531\n",
      "Embedding dimension:  50\n"
     ]
    }
   ],
   "source": [
    "# Define the architecture of the RNN\n",
    "model = nlp_lstm_embedding(embedding_dict, emotion_categories, verbose=1)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', 'f1_score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 30ms/step - accuracy: 0.4440 - f1_score: 0.2504 - loss: 1.2561 - val_accuracy: 0.5250 - val_f1_score: 0.3038 - val_loss: 1.1241\n",
      "Epoch 2/15\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.5064 - f1_score: 0.3022 - loss: 1.1447 - val_accuracy: 0.5428 - val_f1_score: 0.3628 - val_loss: 1.0669\n",
      "Epoch 3/15\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.5272 - f1_score: 0.3660 - loss: 1.0928 - val_accuracy: 0.5744 - val_f1_score: 0.4386 - val_loss: 0.9975\n",
      "Epoch 4/15\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.5709 - f1_score: 0.4473 - loss: 1.0272 - val_accuracy: 0.6215 - val_f1_score: 0.5484 - val_loss: 0.9342\n",
      "Epoch 5/15\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.5946 - f1_score: 0.5112 - loss: 0.9904 - val_accuracy: 0.6502 - val_f1_score: 0.5908 - val_loss: 0.8818\n",
      "Epoch 6/15\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.6307 - f1_score: 0.5622 - loss: 0.9188 - val_accuracy: 0.6887 - val_f1_score: 0.6429 - val_loss: 0.8166\n",
      "Epoch 7/15\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.6534 - f1_score: 0.5978 - loss: 0.8729 - val_accuracy: 0.6967 - val_f1_score: 0.6456 - val_loss: 0.7827\n",
      "Epoch 8/15\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.6764 - f1_score: 0.6228 - loss: 0.8251 - val_accuracy: 0.7254 - val_f1_score: 0.6830 - val_loss: 0.7341\n",
      "Epoch 9/15\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.6933 - f1_score: 0.6478 - loss: 0.7947 - val_accuracy: 0.7387 - val_f1_score: 0.6995 - val_loss: 0.7040\n",
      "Epoch 10/15\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.7118 - f1_score: 0.6707 - loss: 0.7563 - val_accuracy: 0.7530 - val_f1_score: 0.7231 - val_loss: 0.6774\n",
      "Epoch 11/15\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.7296 - f1_score: 0.6897 - loss: 0.7181 - val_accuracy: 0.7645 - val_f1_score: 0.7371 - val_loss: 0.6494\n",
      "Epoch 12/15\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.7306 - f1_score: 0.6937 - loss: 0.7045 - val_accuracy: 0.7714 - val_f1_score: 0.7443 - val_loss: 0.6357\n",
      "Epoch 13/15\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.7392 - f1_score: 0.7009 - loss: 0.6804 - val_accuracy: 0.7662 - val_f1_score: 0.7340 - val_loss: 0.6379\n",
      "Epoch 14/15\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.7517 - f1_score: 0.7185 - loss: 0.6588 - val_accuracy: 0.7679 - val_f1_score: 0.7377 - val_loss: 0.6195\n",
      "Epoch 15/15\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.7564 - f1_score: 0.7206 - loss: 0.6467 - val_accuracy: 0.7760 - val_f1_score: 0.7466 - val_loss: 0.6033\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">476,550</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ masking_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">21,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,368</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │       \u001b[38;5;34m476,550\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ masking_1 (\u001b[38;5;33mMasking\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m21,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m10,368\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m132\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">571,796</span> (2.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m571,796\u001b[0m (2.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,748</span> (124.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,748\u001b[0m (124.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">476,550</span> (1.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m476,550\u001b[0m (1.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,498</span> (248.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m63,498\u001b[0m (248.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_X, train_y, validation_data=(valid_X, valid_y), epochs=15, batch_size=64, callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7912 - f1_score: 0.7653 - loss: 0.5712\n",
      "Test Loss: 0.5643389225006104\n",
      "Test Accuracy: 0.7915493249893188\n",
      "F1 Score: tf.Tensor([0.67956984 0.76415086 0.84890103 0.7751036 ], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "score = model.evaluate(test_X, test_y, return_dict=True, verbose=1)\n",
    "print('Test Loss:', score['loss'])\n",
    "print('Test Accuracy:', score['accuracy'])\n",
    "print('F1 Score:', score['f1_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine of padding size\n",
    "We compared the results by setting pad_size to max_sentence_len (36) (as shown above) and the third quartile (13) (will be demonstrated below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.,  9., 13.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Space usage ratio: 0.3611111111111111\n"
     ]
    }
   ],
   "source": [
    "third_quartile = int(quartiles[2])\n",
    "space_usage_ratio = third_quartile / max_sentence_len\n",
    "print(f\"Space usage ratio: {space_usage_ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pad_sequences(tokenizer.texts_to_sequences(train_txt), maxlen=third_quartile, padding='post')\n",
    "valid_X = pad_sequences(tokenizer.texts_to_sequences(valid_txt), maxlen=third_quartile, padding='post')\n",
    "test_X  = pad_sequences(tokenizer.texts_to_sequences(test_txt) , maxlen=third_quartile, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size:  9531\n",
      "Embedding dimension:  50\n"
     ]
    }
   ],
   "source": [
    "# setting the max_len to third quartile and train the model again\n",
    "model = nlp_lstm_embedding(embedding_dict, emotion_categories, verbose=1)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', 'f1_score'])\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.4337 - f1_score: 0.2527 - loss: 1.2651 - val_accuracy: 0.5325 - val_f1_score: 0.3099 - val_loss: 1.1253\n",
      "Epoch 2/15\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.5060 - f1_score: 0.3138 - loss: 1.1516 - val_accuracy: 0.5307 - val_f1_score: 0.3285 - val_loss: 1.0682\n",
      "Epoch 3/15\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.5291 - f1_score: 0.3892 - loss: 1.0979 - val_accuracy: 0.5807 - val_f1_score: 0.4454 - val_loss: 1.0040\n",
      "Epoch 4/15\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.5616 - f1_score: 0.4617 - loss: 1.0440 - val_accuracy: 0.6221 - val_f1_score: 0.5556 - val_loss: 0.9456\n",
      "Epoch 5/15\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.5923 - f1_score: 0.5070 - loss: 0.9843 - val_accuracy: 0.6485 - val_f1_score: 0.5669 - val_loss: 0.8882\n",
      "Epoch 6/15\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.6152 - f1_score: 0.5534 - loss: 0.9528 - val_accuracy: 0.6783 - val_f1_score: 0.6130 - val_loss: 0.8370\n",
      "Epoch 7/15\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6479 - f1_score: 0.5880 - loss: 0.8831 - val_accuracy: 0.6956 - val_f1_score: 0.6518 - val_loss: 0.7871\n",
      "Epoch 8/15\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.6722 - f1_score: 0.6277 - loss: 0.8375 - val_accuracy: 0.7151 - val_f1_score: 0.6635 - val_loss: 0.7619\n",
      "Epoch 9/15\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6849 - f1_score: 0.6363 - loss: 0.7956 - val_accuracy: 0.7295 - val_f1_score: 0.6964 - val_loss: 0.7130\n",
      "Epoch 10/15\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6998 - f1_score: 0.6546 - loss: 0.7855 - val_accuracy: 0.7392 - val_f1_score: 0.7016 - val_loss: 0.6984\n",
      "Epoch 11/15\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7121 - f1_score: 0.6695 - loss: 0.7401 - val_accuracy: 0.7507 - val_f1_score: 0.7157 - val_loss: 0.6756\n",
      "Epoch 12/15\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7246 - f1_score: 0.6875 - loss: 0.7304 - val_accuracy: 0.7542 - val_f1_score: 0.7148 - val_loss: 0.6651\n",
      "Epoch 13/15\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7298 - f1_score: 0.6947 - loss: 0.7091 - val_accuracy: 0.7582 - val_f1_score: 0.7238 - val_loss: 0.6461\n",
      "Epoch 14/15\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.7403 - f1_score: 0.7057 - loss: 0.6979 - val_accuracy: 0.7570 - val_f1_score: 0.7214 - val_loss: 0.6407\n",
      "Epoch 15/15\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7434 - f1_score: 0.7092 - loss: 0.6834 - val_accuracy: 0.7645 - val_f1_score: 0.7312 - val_loss: 0.6406\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">476,550</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ masking_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">21,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,368</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │       \u001b[38;5;34m476,550\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ masking_2 (\u001b[38;5;33mMasking\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_4 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m21,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_5 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m10,368\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m132\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">571,796</span> (2.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m571,796\u001b[0m (2.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,748</span> (124.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,748\u001b[0m (124.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">476,550</span> (1.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m476,550\u001b[0m (1.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,498</span> (248.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m63,498\u001b[0m (248.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_X, train_y, validation_data=(valid_X, valid_y), epochs=15, batch_size=64, callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7756 - f1_score: 0.7550 - loss: 0.6081\n",
      "Test Loss: 0.6105379462242126\n",
      "Test Accuracy: 0.7735211253166199\n",
      "F1 Score: tf.Tensor([0.68979585 0.7158836  0.8305555  0.7604433 ], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "score = model.evaluate(test_X, test_y, return_dict=True)\n",
    "print('Test Loss:', score['loss'])\n",
    "print('Test Accuracy:', score['accuracy'])\n",
    "print('F1 Score:', score['f1_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training input space of using the third quartile of sentences lengths is only 0.36 of that using the maximum of sentences lengths. And it performs similarly well.\n",
    "\n",
    "In the following sections, we will set padding size to the third quartile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove + Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from nlp_model import nlp_hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third_quartile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size:  9531\n",
      "Embedding dimension:  50\n"
     ]
    }
   ],
   "source": [
    "## Hyperparameter tuning\n",
    "tuner_hb = kt.Hyperband(\n",
    "    hypermodel=lambda hp: nlp_hyperparam(hp=hp, embedding_dict=embedding_dict, verbose=1), # hypermodel=nlp_hyperparam(embedding_dict=embedding_dict, input_length=third_quartile),\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=12,\n",
    "    factor=3,\n",
    "    overwrite=True,\n",
    "    directory=\"hp_tuning\",\n",
    "    project_name=\"hyperband\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "model_type (Choice)\n",
      "{'default': 'single_LSTM', 'conditions': [], 'values': ['single_LSTM', 'bidir_LSTM'], 'ordered': False}\n",
      "lr (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
      "dropout (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 64, 'step': 16, 'sampling': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "tuner = tuner_hb\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 38s]\n",
      "val_accuracy: 0.805284321308136\n",
      "\n",
      "Best val_accuracy So Far: 0.805284321308136\n",
      "Total elapsed time: 00h 09m 02s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(train_X, train_y, epochs=18, validation_data=(valid_X, valid_y), batch_size=64, callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size:  9531\n",
      "Embedding dimension:  50\n",
      "Training data size:  9531\n",
      "Embedding dimension:  50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">476,550</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ masking (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">58,880</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │       \u001b[38;5;34m476,550\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ masking (\u001b[38;5;33mMasking\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m58,880\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m516\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">634,762</span> (2.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m634,762\u001b[0m (2.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">158,212</span> (618.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m158,212\u001b[0m (618.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">476,550</span> (1.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m476,550\u001b[0m (1.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = tuner.get_best_models(num_models=2)\n",
    "best_model = models[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the model\n",
    "# test_loss, test_acc = best_model.evaluate(test_X, test_y)\n",
    "# print('Test Loss:', test_loss)\n",
    "# print('Test Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8019 - f1_score: 0.7866 - loss: 0.5363\n",
      "Test Loss: 0.5167815685272217\n",
      "Test Accuracy: 0.8157746195793152\n",
      "F1 Score: tf.Tensor([0.7549407  0.7860464  0.8662873  0.79304624], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "score = best_model.evaluate(test_X, test_y, return_dict=True)\n",
    "print('Test Loss:', score['loss'])\n",
    "print('Test Accuracy:', score['accuracy'])\n",
    "print('F1 Score:', score['f1_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_type': 'bidir_LSTM',\n",
       " 'lr': 0.007598629268102825,\n",
       " 'dropout': 0.1,\n",
       " 'units': 64,\n",
       " 'tuner/epochs': 12,\n",
       " 'tuner/initial_epoch': 0,\n",
       " 'tuner/bracket': 0,\n",
       " 'tuner/round': 0}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get hyperparameters of the best model\n",
    "best_hps = tuner.get_best_hyperparameters()[0]\n",
    "best_hps.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "For the bag of words method, the input size of each training data is 9531. Constructing and training the DNN model, we obtain 0.89 accuracy. The accuracy is pretty good, but one of the disadvantages is obvious that it requires too many spaces and is too sparse.\n",
    "\n",
    "For the padding sequence method with pretrained GloVe word-to-vector model, the input size of each training data is 13 x 50 = 650. Constructing and training the LSTM model, we obtain 0.82 accuracy. Although the accuracy is not better than one from the bag of words method, it requires much less spaces.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
